{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ya anjir cpt bgt ya abis barang manusia diskon:(</td>\n",
       "      <td>SOHEEDCH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lazada 11.11.2019 diskon terbesar 24 jam https...</td>\n",
       "      <td>Vallno_07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>selama kalo liat promo diskon 70% + 30% dalem ...</td>\n",
       "      <td>bayu_joo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>apa bedanya matahari sama bulan?  matahari ada...</td>\n",
       "      <td>Hanifati_f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@garudacares bagaimana cara tukar mileage disk...</td>\n",
       "      <td>Nug_QA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>@gencamon nahiya benerrr hahahaha kalo makan c...</td>\n",
       "      <td>primetam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>fak gmarket kenapa diskon nya sekarang sih</td>\n",
       "      <td>singularyv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>sejarah asia tenggara karya m.c. ricklefs rp 3...</td>\n",
       "      <td>KomunitasBambu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>@amingcoffee transmart kuburaya diskon, kapan ...</td>\n",
       "      <td>kalbarinfo_</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>tah diskon 50% cenah..  yuk diserbu..   https:...</td>\n",
       "      <td>AmaAbiyyunShoh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>@wongalas901 @prabowo @aniesbaswedan rika wis ...</td>\n",
       "      <td>Dianhandoko6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>sebenarnya bahagia itu sederhana... - beli ini...</td>\n",
       "      <td>anggieppu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>yuhuu..  siapa lagi yang mau order deodorantny...</td>\n",
       "      <td>indri_indriyuni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>@febjae iya teh ambil aja yang kuning mah. dis...</td>\n",
       "      <td>favechan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>pesta harga akhir tahun di giias medan auto sh...</td>\n",
       "      <td>IcanIndopro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>yaampun kak aulll. eh tapi itu make over lagi ...</td>\n",
       "      <td>tyoungjaems</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>@rahagyu29 @bayu_joo jadi misal harganya 100rb...</td>\n",
       "      <td>gardagagar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>pesta harga akhir tahun di giias medan auto sh...</td>\n",
       "      <td>IcanIndopro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>hanya hari ini! shopee promo 11.11 big sale! 1...</td>\n",
       "      <td>katalogpromosi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>@tys1004 mau beli season greetings tia, per ha...</td>\n",
       "      <td>ChocoBee_</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>cgv cinemas kini hadir di icon mall #gresik . ...</td>\n",
       "      <td>GoersApp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>@princekuaniin fansite kyknya soalnya itu pun ...</td>\n",
       "      <td>aracelli_0129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>beli tiket kereta api di @tokopedia diskon 20%...</td>\n",
       "      <td>promo_BRI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>buat kalian yang bisa jajan di alfamart - yuk ...</td>\n",
       "      <td>katalogpromosi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>starbucks promo diskon 50% untuk pembelian min...</td>\n",
       "      <td>katalogpromosi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>sempurnakan alat dapurmu yuk! peralatan dapur ...</td>\n",
       "      <td>alfacartID</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>@gramedia handmaid's tale belum ketemu miinn d...</td>\n",
       "      <td>Ljwoori</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>@yrachmania temen gue nitip temennya pas di ho...</td>\n",
       "      <td>urpoisonivy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>{np} 6 tiket diskon 50% masuk gelanggang samud...</td>\n",
       "      <td>New_preloved</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>kalok minta diskon, telponnyaaaa berkali kalii...</td>\n",
       "      <td>Kmunadiayuna</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>lewat aplikasi ini, bisa reservasi restoran pl...</td>\n",
       "      <td>foodball33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>lewat aplikasi ini, bisa reservasi restoran pl...</td>\n",
       "      <td>SayaSukaMasak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>lewat aplikasi ini, bisa reservasi restoran pl...</td>\n",
       "      <td>redyvine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>lewat aplikasi ini, bisa reservasi restoran pl...</td>\n",
       "      <td>lezatbergizi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>lewat aplikasi ini, bisa reservasi restoran pl...</td>\n",
       "      <td>fbrdn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>lewat aplikasi ini, bisa reservasi restoran pl...</td>\n",
       "      <td>FineCuisineSmg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>dapatkan tambahan diskon hingga 10% khusus bag...</td>\n",
       "      <td>KartuKreditBCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>@tchallabae diskon kahh???</td>\n",
       "      <td>ZKDLIN88kai</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>cardholders, sudah waktunya mengganti springbe...</td>\n",
       "      <td>mandiricard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>harga gledek 1 hari lagi! nikmati diskon tiket...</td>\n",
       "      <td>tiket</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>dibuka prapesan!  mencari bali yang berubah ka...</td>\n",
       "      <td>basabasi_store</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>@vindayp diskon akhir tahun dong</td>\n",
       "      <td>sighatullah</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>183</td>\n",
       "      <td>cobaan apa ini pilih yg (sedang diskon 50 pers...</td>\n",
       "      <td>boo_tato</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>184</td>\n",
       "      <td>@izonechoiyena ngga kok, cuma lagi diskon aja.</td>\n",
       "      <td>ddeulguom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>@womanfeeds shinzui.. sering diskon di alfa in...</td>\n",
       "      <td>migumiguya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>kampanye 11.11 ini akan berlangsung 10 hari mu...</td>\n",
       "      <td>kompascom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>187</td>\n",
       "      <td>starbucks promo diskon 50% untuk pembelian min...</td>\n",
       "      <td>katalogpromosi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>#repost hushpuppiesid          calm your day w...</td>\n",
       "      <td>Park23Bali</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>#rt @generasimilenia: diskon dan bonus goda pe...</td>\n",
       "      <td>infoinfokeren</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>#jalanjalangratis #ngilanginstres #ngilanginst...</td>\n",
       "      <td>TiketPesawatPro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>@husen_jafar @na_dirs ilmu dan diskon fungsiny...</td>\n",
       "      <td>_Sai_ful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>@syikapn tltsn lagi diskon ya de? masi banyak ...</td>\n",
       "      <td>pristiaudiaa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>diskon 40% dari harga normal</td>\n",
       "      <td>IkigawaLee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>194</td>\n",
       "      <td>@_sai_ful @na_dirs aku sudah ngasih ilmu, masa...</td>\n",
       "      <td>Husen_Jafar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>kemarin sebelum ke maiyah, sempet nonton ini j...</td>\n",
       "      <td>ShadaHanin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>cukup dengan membawa minimal 2 orang pendampin...</td>\n",
       "      <td>ancoltmnimpian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>@zefanyaruth @ohmybeautybank legging airism en...</td>\n",
       "      <td>deenoora</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>2 bioglass 4jt dapet diskon 300rb dapet lagi g...</td>\n",
       "      <td>sellyriantica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>@womanfeeds wahh yg bener diskon?</td>\n",
       "      <td>fitriindaahp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>masuk bulan november banyak email dan sms ngas...</td>\n",
       "      <td>thirteeniaa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                  0  \\\n",
       "0             0   ya anjir cpt bgt ya abis barang manusia diskon:(   \n",
       "1             1  lazada 11.11.2019 diskon terbesar 24 jam https...   \n",
       "2             2  selama kalo liat promo diskon 70% + 30% dalem ...   \n",
       "3             3  apa bedanya matahari sama bulan?  matahari ada...   \n",
       "4             4  @garudacares bagaimana cara tukar mileage disk...   \n",
       "5             5  @gencamon nahiya benerrr hahahaha kalo makan c...   \n",
       "6             6         fak gmarket kenapa diskon nya sekarang sih   \n",
       "7             7  sejarah asia tenggara karya m.c. ricklefs rp 3...   \n",
       "8             8  @amingcoffee transmart kuburaya diskon, kapan ...   \n",
       "9             9  tah diskon 50% cenah..  yuk diserbu..   https:...   \n",
       "10           10  @wongalas901 @prabowo @aniesbaswedan rika wis ...   \n",
       "11           11  sebenarnya bahagia itu sederhana... - beli ini...   \n",
       "12           12  yuhuu..  siapa lagi yang mau order deodorantny...   \n",
       "13           13  @febjae iya teh ambil aja yang kuning mah. dis...   \n",
       "14           14  pesta harga akhir tahun di giias medan auto sh...   \n",
       "15           15  yaampun kak aulll. eh tapi itu make over lagi ...   \n",
       "16           16  @rahagyu29 @bayu_joo jadi misal harganya 100rb...   \n",
       "17           17  pesta harga akhir tahun di giias medan auto sh...   \n",
       "18           18  hanya hari ini! shopee promo 11.11 big sale! 1...   \n",
       "19           19  @tys1004 mau beli season greetings tia, per ha...   \n",
       "20           20  cgv cinemas kini hadir di icon mall #gresik . ...   \n",
       "21           21  @princekuaniin fansite kyknya soalnya itu pun ...   \n",
       "22           22  beli tiket kereta api di @tokopedia diskon 20%...   \n",
       "23           23  buat kalian yang bisa jajan di alfamart - yuk ...   \n",
       "24           24  starbucks promo diskon 50% untuk pembelian min...   \n",
       "25           25  sempurnakan alat dapurmu yuk! peralatan dapur ...   \n",
       "26           26  @gramedia handmaid's tale belum ketemu miinn d...   \n",
       "27           27  @yrachmania temen gue nitip temennya pas di ho...   \n",
       "28           28  {np} 6 tiket diskon 50% masuk gelanggang samud...   \n",
       "29           29  kalok minta diskon, telponnyaaaa berkali kalii...   \n",
       "..          ...                                                ...   \n",
       "171         171  lewat aplikasi ini, bisa reservasi restoran pl...   \n",
       "172         172  lewat aplikasi ini, bisa reservasi restoran pl...   \n",
       "173         173  lewat aplikasi ini, bisa reservasi restoran pl...   \n",
       "174         174  lewat aplikasi ini, bisa reservasi restoran pl...   \n",
       "175         175  lewat aplikasi ini, bisa reservasi restoran pl...   \n",
       "176         176  lewat aplikasi ini, bisa reservasi restoran pl...   \n",
       "177         177  dapatkan tambahan diskon hingga 10% khusus bag...   \n",
       "178         178                         @tchallabae diskon kahh???   \n",
       "179         179  cardholders, sudah waktunya mengganti springbe...   \n",
       "180         180  harga gledek 1 hari lagi! nikmati diskon tiket...   \n",
       "181         181  dibuka prapesan!  mencari bali yang berubah ka...   \n",
       "182         182                   @vindayp diskon akhir tahun dong   \n",
       "183         183  cobaan apa ini pilih yg (sedang diskon 50 pers...   \n",
       "184         184     @izonechoiyena ngga kok, cuma lagi diskon aja.   \n",
       "185         185  @womanfeeds shinzui.. sering diskon di alfa in...   \n",
       "186         186  kampanye 11.11 ini akan berlangsung 10 hari mu...   \n",
       "187         187  starbucks promo diskon 50% untuk pembelian min...   \n",
       "188         188  #repost hushpuppiesid          calm your day w...   \n",
       "189         189  #rt @generasimilenia: diskon dan bonus goda pe...   \n",
       "190         190  #jalanjalangratis #ngilanginstres #ngilanginst...   \n",
       "191         191  @husen_jafar @na_dirs ilmu dan diskon fungsiny...   \n",
       "192         192  @syikapn tltsn lagi diskon ya de? masi banyak ...   \n",
       "193         193                       diskon 40% dari harga normal   \n",
       "194         194  @_sai_ful @na_dirs aku sudah ngasih ilmu, masa...   \n",
       "195         195  kemarin sebelum ke maiyah, sempet nonton ini j...   \n",
       "196         196  cukup dengan membawa minimal 2 orang pendampin...   \n",
       "197         197  @zefanyaruth @ohmybeautybank legging airism en...   \n",
       "198         198  2 bioglass 4jt dapet diskon 300rb dapet lagi g...   \n",
       "199         199                  @womanfeeds wahh yg bener diskon?   \n",
       "200         200  masuk bulan november banyak email dan sms ngas...   \n",
       "\n",
       "                   1  2  \n",
       "0           SOHEEDCH  0  \n",
       "1          Vallno_07  1  \n",
       "2           bayu_joo  0  \n",
       "3         Hanifati_f  0  \n",
       "4             Nug_QA  1  \n",
       "5           primetam  0  \n",
       "6         singularyv  0  \n",
       "7     KomunitasBambu  1  \n",
       "8        kalbarinfo_  0  \n",
       "9     AmaAbiyyunShoh  1  \n",
       "10      Dianhandoko6  0  \n",
       "11         anggieppu  0  \n",
       "12   indri_indriyuni  0  \n",
       "13          favechan  0  \n",
       "14       IcanIndopro  0  \n",
       "15       tyoungjaems  1  \n",
       "16        gardagagar  0  \n",
       "17       IcanIndopro  1  \n",
       "18    katalogpromosi  1  \n",
       "19         ChocoBee_  0  \n",
       "20          GoersApp  1  \n",
       "21     aracelli_0129  0  \n",
       "22         promo_BRI  1  \n",
       "23    katalogpromosi  1  \n",
       "24    katalogpromosi  1  \n",
       "25        alfacartID  1  \n",
       "26           Ljwoori  0  \n",
       "27       urpoisonivy  1  \n",
       "28      New_preloved  0  \n",
       "29      Kmunadiayuna  0  \n",
       "..               ... ..  \n",
       "171       foodball33  1  \n",
       "172    SayaSukaMasak  1  \n",
       "173         redyvine  1  \n",
       "174     lezatbergizi  1  \n",
       "175            fbrdn  1  \n",
       "176   FineCuisineSmg  1  \n",
       "177   KartuKreditBCA  1  \n",
       "178      ZKDLIN88kai  0  \n",
       "179      mandiricard  1  \n",
       "180            tiket  1  \n",
       "181   basabasi_store  1  \n",
       "182      sighatullah  0  \n",
       "183         boo_tato  0  \n",
       "184        ddeulguom  0  \n",
       "185       migumiguya  0  \n",
       "186        kompascom  0  \n",
       "187   katalogpromosi  1  \n",
       "188       Park23Bali  1  \n",
       "189    infoinfokeren  0  \n",
       "190  TiketPesawatPro  1  \n",
       "191         _Sai_ful  0  \n",
       "192     pristiaudiaa  0  \n",
       "193       IkigawaLee  0  \n",
       "194      Husen_Jafar  0  \n",
       "195       ShadaHanin  1  \n",
       "196   ancoltmnimpian  1  \n",
       "197         deenoora  0  \n",
       "198    sellyriantica  1  \n",
       "199     fitriindaahp  0  \n",
       "200      thirteeniaa  0  \n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('integrated_data/integrated_with_label.csv', sep=',', encoding='latin-1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ya anjir cpt bgt ya abis barang manusia diskon:(</td>\n",
       "      <td>SOHEEDCH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lazada 11.11.2019 diskon terbesar 24 jam https...</td>\n",
       "      <td>Vallno_07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>selama kalo liat promo diskon 70% + 30% dalem ...</td>\n",
       "      <td>bayu_joo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>apa bedanya matahari sama bulan?  matahari ada...</td>\n",
       "      <td>Hanifati_f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@garudacares bagaimana cara tukar mileage disk...</td>\n",
       "      <td>Nug_QA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0           1  \\\n",
       "0           0   ya anjir cpt bgt ya abis barang manusia diskon:(    SOHEEDCH   \n",
       "1           1  lazada 11.11.2019 diskon terbesar 24 jam https...   Vallno_07   \n",
       "2           2  selama kalo liat promo diskon 70% + 30% dalem ...    bayu_joo   \n",
       "3           3  apa bedanya matahari sama bulan?  matahari ada...  Hanifati_f   \n",
       "4           4  @garudacares bagaimana cara tukar mileage disk...      Nug_QA   \n",
       "\n",
       "   2  \n",
       "0  0  \n",
       "1  1  \n",
       "2  0  \n",
       "3  0  \n",
       "4  1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Unnamed: 0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.0</td>\n",
       "      <td>102.011364</td>\n",
       "      <td>62.579144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.75</td>\n",
       "      <td>105.5</td>\n",
       "      <td>154.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113.0</td>\n",
       "      <td>98.433628</td>\n",
       "      <td>54.720210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                                        \n",
       "       count        mean        std  min    25%    50%    75%    max\n",
       "2                                                                   \n",
       "0       88.0  102.011364  62.579144  0.0  44.75  105.5  154.0  200.0\n",
       "1      113.0   98.433628  54.720210  1.0  53.00   96.0  145.0  198.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('2').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(msg):\n",
    "    clean = [char for char in msg if char not in string.punctuation]\n",
    "    clean = ''.join(clean)\n",
    "    return clean.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bocan', 'suka', 'mencuri', 'timun']\n"
     ]
    }
   ],
   "source": [
    "m = tokenize(\"Bocan??? Suka mencuri timun...\")\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_of_word = CountVectorizer(analyzer=tokenize).fit(data['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721\n"
     ]
    }
   ],
   "source": [
    "print(len(bag_of_word.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sejarah asia tenggara karya m.c. ricklefs rp 350.000 diskon rp 210.000  order: https://t.co/vietimemom  atau   wa 0813-8543-0505 komunitas bambu jl. taufiqurrahman no.3 beji timur, depok  buka senin-jumat pukul 08.00-17.00 wib  #komunitasbambu #sejarahasiatenggara https://t.co/xxdt22uodi\n"
     ]
    }
   ],
   "source": [
    "msg = data['0'][7]\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow = bag_of_word.transform([msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 39)\t1\n",
      "  (0, 58)\t1\n",
      "  (0, 161)\t1\n",
      "  (0, 166)\t1\n",
      "  (0, 194)\t1\n",
      "  (0, 222)\t1\n",
      "  (0, 306)\t1\n",
      "  (0, 388)\t1\n",
      "  (0, 426)\t1\n",
      "  (0, 739)\t1\n",
      "  (0, 745)\t1\n",
      "  (0, 827)\t1\n",
      "  (0, 876)\t1\n",
      "  (0, 928)\t1\n",
      "  (0, 929)\t1\n",
      "  (0, 1055)\t1\n",
      "  (0, 1165)\t1\n",
      "  (0, 1205)\t1\n",
      "  (0, 1315)\t1\n",
      "  (0, 1352)\t1\n",
      "  (0, 1358)\t2\n",
      "  (0, 1415)\t1\n",
      "  (0, 1416)\t1\n",
      "  (0, 1447)\t1\n",
      "  (0, 1550)\t1\n",
      "  (0, 1563)\t1\n",
      "  (0, 1593)\t1\n",
      "  (0, 1661)\t1\n",
      "  (0, 1682)\t1\n",
      "(1, 1721)\n"
     ]
    }
   ],
   "source": [
    "print(bow)\n",
    "print(bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longdress\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_word.get_feature_names()[990])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = bag_of_word.transform(data['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 41 201\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(data['0'], data['2'], test_size=0.2)\n",
    "\n",
    "print(len(x_train), len(x_test), len(x_train) + len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetworkBinaryClassifier:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_layers=(3,2),\n",
    "        batch_size=1,\n",
    "        momentum=0.9,\n",
    "        learning_rate=1e-3,\n",
    "        n_iteration=100\n",
    "    ):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.momentum = momentum\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iteration = n_iteration\n",
    "        \n",
    "    def _error(self, pred, target, derive=False):\n",
    "        if derive:\n",
    "            return (pred - target) / (pred - np.square(pred))\n",
    "        return -(np.log(pred) if target > 0 else np.log(1.0 - pred)),\n",
    "        \n",
    "    def _activation(self, x, derive=False):\n",
    "        if derive:\n",
    "            return self._activation(x) * (1.0 - self._activation(x))\n",
    "        return 1.0 / (1.0 + np.exp(-x))            \n",
    "        \n",
    "    def _init_parameters(self, input_size):\n",
    "        last_output = input_size\n",
    "        self.weights = []\n",
    "        for layer_size in self.hidden_layers + (1,):\n",
    "            limit = np.sqrt(6 / (last_output + layer_size))\n",
    "            self.weights.append(np.random.rand(last_output + 1, layer_size) * limit * 2 - limit)\n",
    "            last_output = layer_size\n",
    "            \n",
    "    def predict(self, test_x):\n",
    "        input_vector = test_x\n",
    "        for w in self.weights:\n",
    "            input_vector = np.append(input_vector, np.ones((len(input_vector), 1)), axis=1)\n",
    "            input_vector = self._activation(np.dot(input_vector, w))\n",
    "        return np.heaviside(input_vector - 0.5, 1.0)\n",
    "        \n",
    "    def fit(self, train_x, train_y):\n",
    "        n, input_dim = train_x.shape\n",
    "        bz = self.batch_size\n",
    "        self._init_parameters(input_dim)\n",
    "        depth = len(self.weights)\n",
    "        \n",
    "        # initialize previous update for momentum\n",
    "        last_weights_update = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        for _ in range(self.n_iteration):            \n",
    "            batch_x = np.array_split(train_x, range(bz, n, bz))\n",
    "            batch_y = np.array_split(train_y, range(bz, n, bz))\n",
    "            for x, y in zip(batch_x, batch_y):\n",
    "                last_sum_output = [np.zeros(w.shape[1]) for w in self.weights]\n",
    "                last_input = [np.zeros(w.shape[0]) for w in self.weights]\n",
    "\n",
    "                input_vector, target_vector = x, y.reshape((len(x), 1))\n",
    "                for i, w in enumerate(self.weights):\n",
    "                    input_vector = np.append(input_vector, np.ones((len(input_vector), 1)), axis=1)\n",
    "                    last_input[i] += np.sum(input_vector, axis=0)\n",
    "                    sum_value = np.dot(input_vector, w)\n",
    "                    input_vector = self._activation(sum_value)\n",
    "                    last_sum_output[i] += np.sum(sum_value, axis=0)\n",
    "                    \n",
    "                # calculate loss gradient of current batch by predicted output\n",
    "                batch_loss_grad = self._error(input_vector, target_vector, True)\n",
    "                avg_batch_loss_grad = np.average(batch_loss_grad)\n",
    "                \n",
    "                for ls_input, ls_sum_output in zip(last_input, last_sum_output):\n",
    "                    ls_input /= x.shape[0]\n",
    "                    ls_sum_output /= x.shape[0]\n",
    "                    \n",
    "                propagated_grad_error = avg_batch_loss_grad\n",
    "                for i in reversed(range(depth)):\n",
    "                    propagated_grad_error *= self._activation(last_sum_output[i], True)\n",
    "                    d_weight = np.dot(\n",
    "                        np.array([last_input[i]]).T,\n",
    "                        np.array([propagated_grad_error])\n",
    "                    )\n",
    "                    propagated_grad_error = np.dot(propagated_grad_error, self.weights[i].T)[:-1]\n",
    "                    update_weight = self.learning_rate * d_weight + last_weights_update[i] * self.momentum\n",
    "                    self.weights[i] -= update_weight\n",
    "                    last_weights_update[i] = update_weight\n",
    "                \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1682)\t0.18440417303669154\n",
      "  (0, 1661)\t0.16164077334820637\n",
      "  (0, 1593)\t0.18440417303669154\n",
      "  (0, 1563)\t0.17108843783000008\n",
      "  (0, 1550)\t0.18440417303669154\n",
      "  (0, 1447)\t0.18440417303669154\n",
      "  (0, 1416)\t0.18440417303669154\n",
      "  (0, 1415)\t0.17108843783000008\n",
      "  (0, 1358)\t0.2700186058696469\n",
      "  (0, 1352)\t0.18440417303669154\n",
      "  (0, 1315)\t0.18440417303669154\n",
      "  (0, 1205)\t0.1483250381415149\n",
      "  (0, 1165)\t0.18440417303669154\n",
      "  (0, 1055)\t0.18440417303669154\n",
      "  (0, 929)\t0.18440417303669154\n",
      "  (0, 928)\t0.18440417303669154\n",
      "  (0, 876)\t0.17108843783000008\n",
      "  (0, 827)\t0.18440417303669154\n",
      "  (0, 745)\t0.18440417303669154\n",
      "  (0, 739)\t0.18440417303669154\n",
      "  (0, 426)\t0.03349747861631423\n",
      "  (0, 388)\t0.18440417303669154\n",
      "  (0, 306)\t0.14326263056694333\n",
      "  (0, 222)\t0.18440417303669154\n",
      "  (0, 194)\t0.18440417303669154\n",
      "  (0, 166)\t0.16164077334820637\n",
      "  (0, 161)\t0.17108843783000008\n",
      "  (0, 58)\t0.18440417303669154\n",
      "  (0, 39)\t0.18440417303669154\n",
      "  (0, 5)\t0.18440417303669154\n",
      "  (0, 3)\t0.18440417303669154\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer().fit(messages)\n",
    "\n",
    "tfidf9 = tfidf.transform(bow)\n",
    "print(tfidf9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 1721)\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf.transform(messages)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuronLayer:\n",
    "    def __init__(self,input_count, node_count, init_weight, random_weight=True):\n",
    "        self.weight_matrix = np.full((input_count, node_count), init_weight)\n",
    "        if (random_weight):\n",
    "            self.randomize_weight(init_weight)\n",
    "        self.weight_before = np.full((input_count, node_count), 0)\n",
    "        self.weight_delta = np.zeros((input_count, node_count), dtype=float)\n",
    "        \n",
    "    def randomize_weight(self, init_weight):\n",
    "        for i in range(len(self.weight_matrix)):\n",
    "            for j in range(len(self.weight_matrix[i])):\n",
    "                weight = random.uniform(abs(init_weight)*(-1),abs(init_weight))\n",
    "                self.weight_matrix[i][j] = weight\n",
    "    \n",
    "    def feed(self, data):\n",
    "        net_result = np.dot(data, self.weight_matrix)\n",
    "        result = self.apply_activation(net_result)\n",
    "        self.error_matrix = np.zeros(len(result))\n",
    "        return result\n",
    "    \n",
    "    def apply_activation(self, net_data):\n",
    "        sig_data = np.zeros(len(net_data))\n",
    "\n",
    "        for i in range(len(net_data)):\n",
    "            sig_data[i] = self.sigmoid(net_data[i])\n",
    "        \n",
    "        return sig_data\n",
    "        \n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "    \n",
    "    def generate_sum_weight_error(self, next_weight_matrix, next_error_matrix):\n",
    "        sum_error = 0\n",
    "        for i in range(len(next_weight_matrix)):\n",
    "            sum_error = sum_error + (next_error_matrix[i] * next_weight_matrix[i])\n",
    "        return(sum_error)\n",
    "    \n",
    "    def error_hidden(self, output, sum_next_error_output, i):\n",
    "        result = output*(1-output)*(sum_next_error_output)\n",
    "        return(result)\n",
    "    \n",
    "    def generate_output_error_matrix(self, error_output):\n",
    "        for i in range(len(error_output)):\n",
    "            self.error_matrix[i] = error_output[i]\n",
    "    \n",
    "    def generate_error_matrix(self, output, error_output_next, weight_next):\n",
    "        for i in range(len(output)):\n",
    "            sum_error = self.generate_sum_weight_error(weight_next[i], error_output_next)\n",
    "            self.error_matrix[i] = self.error_hidden(output[i], sum_error, i)\n",
    "\n",
    "    def update_delta_weight(self, momentum, weight_before, learning_rate, error_hidden, single_data):\n",
    "        #print(\"ERROR HIDDEN\",error_hidden)\n",
    "        return(momentum * weight_before + learning_rate * error_hidden * single_data)\n",
    "    \n",
    "    def update_weight_matrix(self):\n",
    "        new_weight_matrix = self.weight_matrix.copy()\n",
    "        for j in range(len(self.error_matrix)):\n",
    "            for i in range(len(self.weight_matrix)):\n",
    "                new_weight_matrix[i] = self.weight_matrix[i] + self.weight_delta[i]\n",
    "                self.weight_before[i] = self.weight_matrix[i]\n",
    "                self.weight_matrix[i] = new_weight_matrix[i]\n",
    "                self.weight_delta[i] = 0\n",
    "                \n",
    "    def update_weight_delta_matrix(self, momentum, learning_rate, input_datas):\n",
    "        for j in range(len(self.error_matrix)):\n",
    "            for i in range(len(self.weight_matrix)):\n",
    "                self.weight_delta[i] += self.update_delta_weight(momentum, self.weight_before[i], \n",
    "                                                                learning_rate, self.error_matrix[j], input_datas[i])\n",
    "        #print(\"WEIGHT DELTA\",self.weight_delta[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    max_hidden_layer = 10\n",
    "    def __init__(self, input_dim, nodes_counts_matrix, init_weight, random_weight=True):\n",
    "        if (len(nodes_counts_matrix) <= self.max_hidden_layer):\n",
    "            input_column_count = input_dim\n",
    "            self.hidden_layer = len(nodes_counts_matrix)\n",
    "            self.layer = []\n",
    "            self.layer_output = []\n",
    "            for i in range(self.hidden_layer):\n",
    "                if (i == 0):\n",
    "                    self.layer.append(NeuronLayer(input_column_count + 1, nodes_counts_matrix[i], init_weight, \n",
    "                                                  random_weight))\n",
    "                else:\n",
    "                    self.layer.append(NeuronLayer(nodes_counts_matrix[i-1] + 1, nodes_counts_matrix[i], init_weight, \n",
    "                                                  random_weight))\n",
    "            self.layer.append(NeuronLayer(nodes_counts_matrix[i] + 1, 1, init_weight, random_weight))\n",
    "        else :\n",
    "            print(\"Hidden Layer Counts exceed\")\n",
    "    \n",
    "    def fit(self, data, target, batch_size, epochs=10, error_threshold=0, learning_rate=0.1, momentum=0):\n",
    "        self.learning_rate =  learning_rate\n",
    "        self.momentum = momentum\n",
    "        for j in range(epochs):\n",
    "            i = 0\n",
    "            error = 0\n",
    "            while(i < len(data)):\n",
    "                error = 0\n",
    "                for k in range (batch_size):\n",
    "                    self.feedforward(data[i])\n",
    "                    self.backpropagation(data[i], target[i])\n",
    "                    error += abs(self.error_output)\n",
    "                    i += 1\n",
    "                #print(\"AAAAAAAAAAAA SUM ERROR\",error[0])\n",
    "                if(error[0] < error_threshold):\n",
    "                    print(\"Error reaching error threshold. Done\")\n",
    "                    return\n",
    "                self.batch_update_weight()\n",
    "                \n",
    "    def predict(self, data):\n",
    "        labels = np.zeros(len(data))\n",
    "        for i in range(len(data)):\n",
    "            label = self.feedforward(data[i])\n",
    "            if (label >= 0.5):\n",
    "                label = 1\n",
    "            else :\n",
    "                label = 0\n",
    "            labels[i] = label\n",
    "        return labels\n",
    "\n",
    "    def generate_error_output(self, output, target):\n",
    "        return(output*(1-output)*(target-output))\n",
    "    \n",
    "    def generate_bias_array(self, ht_array):\n",
    "        ht = ht_array.copy()\n",
    "        ht = np.append(ht, [1])\n",
    "        return(ht)\n",
    "    \n",
    "    def feedforward(self, ht_array):\n",
    "        '''\n",
    "        Feedforward a single data\n",
    "        '''\n",
    "        self.output_layer = []\n",
    "        \n",
    "        ht = self.generate_bias_array(ht_array)\n",
    "        for i in range (self.hidden_layer):\n",
    "            ht = self.layer[i].feed(ht)\n",
    "            ht = self.generate_bias_array(ht)\n",
    "            self.output_layer.append(ht)\n",
    "            \n",
    "        output_result = self.layer[i+1].feed(ht)\n",
    "        #print(\"FINAL OUTPUT\", output_result)\n",
    "        #if (output_result >= 0.5):\n",
    "        #    output_result = 1\n",
    "        #else :\n",
    "        #    output_result = 0\n",
    "        self.output_layer.append(output_result)\n",
    "        return self.output_layer[i+1]\n",
    "    \n",
    "    def backpropagation(self, ht_array, ht_target):\n",
    "        '''\n",
    "        Backprop a single data\n",
    "        '''\n",
    "        i = self.hidden_layer\n",
    "        output = self.output_layer[i]\n",
    "        self.error_output = self.generate_error_output(output, ht_target)\n",
    "        self.layer[i].generate_output_error_matrix(self.error_output)\n",
    "        #print()\n",
    "        #print(\"TARGET\", ht_target)\n",
    "        #print(\"LAYER KE\", i, \"OUTPUT\", output,\"ERROR\",self.error_output, \"WEIGHT MATRIX\", self.layer[i].weight_matrix)\n",
    "        \n",
    "        while(i > 0):\n",
    "            i = i - 1\n",
    "            output = self.output_layer[i][:-1]\n",
    "            next_error = self.layer[i + 1].error_matrix\n",
    "            next_weight = self.layer[i + 1].weight_matrix\n",
    "            #print(\"LAYER KE \", i, \"OUTPUT\",output,\"NEXT ERROR\", next_error,\"NEXT WEIGHT\", next_weight)\n",
    "            self.layer[i].generate_error_matrix(output, next_error, next_weight)\n",
    "        \n",
    "        self.backpropagation_update_weight(ht_array, ht_target)\n",
    "            \n",
    "    def backpropagation_update_weight(self, ht_array, ht_target):\n",
    "        i = 0\n",
    "        ht = self.generate_bias_array(ht_array)\n",
    "        self.layer[i].update_weight_delta_matrix(self.momentum, self.learning_rate, ht)\n",
    "        while((i + 1) <  len(self.layer)):\n",
    "            i = i + 1\n",
    "            ht = self.generate_bias_array(self.output_layer[i-1])\n",
    "            self.layer[i].update_weight_delta_matrix(self.momentum, self.learning_rate, ht)\n",
    "            \n",
    "    def batch_update_weight(self):\n",
    "        i = 0\n",
    "        while(i <  len(self.layer)):\n",
    "            self.layer[i].update_weight_matrix()\n",
    "            i = i + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
